---
title: "EIA vs EBM"
author: "David Beauchesne"
date: "2024-05-02"
categories: [cumulative effects]
image: "wordcloud.png"
draft: true
execute:
  warning: false
format:
  html:
    code-fold: true
    code-summary: "<i><b>Code</b></i>"
---

<!-- 
Notes: 
Table with columns: eia, ebm, both
time
geographies/countries
ecosystems

graph ecosystems ~ process
map countries ~ process
table expression freq eia vs ebm
graph expression ~ process
line graph process ~ year
-->

In my latest post, I performed some semantic analysis and exploration of a [literature review centered on cumulative effects assessment](../review_scientific_literature/). In this post, I want to dive deeper in this review and contrast environmental impact assessments and ecosystem-based management, both of which regularly cite the assessment of cumulative effects in their respective process. Here, ecosystem-based management also encompasses processes such as strategic conservation planning and marine spatial planning, which are essentially ecosystem-based management approaches.

In a nutshell, the assessment of cumulative effects through an environmental impact assessment is usually centered on project-specific appraisal and acceptance unless it is a regional assessment. Cumulative effects viewed through the lense of ecosystem-based management, meanwhile, are more holistic in scope, are usually performed at larger spatial scales and are concerned with the management and monitoring of whole regions. For more information, you can read my blog post that details [what are cumulative effects](../what_are_cumulative_effects/).


# Screening the literature

After programmatically exploring the results of the literature search in [my previous post](../review_scientific_literature/), I manually screened and tagged all the peer-reviewed articles. I was mostly interested in identifying the process each article was interested in (*i.e.* environmental impacts assessment vs ecosystem-based management), the type of ecosystem they worked on (*i.e.* marine, terrestrial or freshwater), and the countries where the work was performed. Through this work, I also removed some articles that made it through the programmatic filtering process done previously but that should have been removed. 




## Articles

```{r}
#| label: data_cleanup
# Get data
# lit <- bib2df::bib2df("cea_screening.bib", separate_names = TRUE, merge_lines = TRUE) |>
lit <- bib2df::bib2df("series/posts/cumulative_effects/eia_vs_ebm/cea_screening.bib", separate_names = TRUE, merge_lines = TRUE) |>
  dplyr::mutate(uid = dplyr::row_number())

# Extract keywords
key <- lit |>
  dplyr::select(uid, KEYWORDS) |>
  dplyr::reframe(key = unlist(stringr::str_split(KEYWORDS, ",")), .by = c(uid)) |>
  tidyr::drop_na() |>
  dplyr::mutate(key = tolower(stringr::str_trim(key, side = "both"))) |>
  dplyr::filter(key != "")


# Check that they all have eia or ebm tag (remove this once completed)
x <- dplyr::group_by(key, by = uid) |>
  dplyr::summarize(check = "eia" %in% key | "ebm" %in% key)




# Table of keywords
table(key$key) |>
  as.data.frame() |>
  dplyr::arrange(dplyr::desc(Freq)) |>
  knitr::kable(col.names = c("Keywords", "Frequency")) |>
  kableExtra::scroll_box(width = "55%", height = "500px")
```


The search and filtering process yielded a total of `r nrow(lit)` peer-reviewed articles. I begin with a classic figure for a literature review, *i.e.* the number of articles through time. The first articles concerned with cumulative effects assessment date back to 1985. Since, we observe a steady increase in the number of articles published, although the last couple of years have seen a dip in the number of articles published concerned with cumulative effects. 

```{r}
#| label: fig-ceafreq
#| fig-cap: Number of articles on cumulative effects assessment published each year.
table(lit$YEAR) |>
  as.data.frame() |>
  echarts4r::e_charts(Var1) |>
  echarts4r::e_bar(Freq, name = "Articles") |>
  echarts4r::e_title("Number of articles per year")
```

## Keywords

Now let's have a look at the keywords identified by the authors. First and without surprise, we see that the search terms that were used for the query on Web of Science are frequently used as keywords. Still, keywords most often used generally refer to the process surrounding the assessment of cumulative effects and environmental management in general. 

```{r}
#| label: tbl-ceakey
#| tbl-cap: Frequency of keywords used literature search on cumulative effects assessment.
# Extract keywords
key <- lit |>
  dplyr::select(uid, KEYWORDS, YEAR) |>
  dplyr::reframe(key = unlist(stringr::str_split(KEYWORDS, ";")), .by = c(YEAR, uid)) |>
  tidyr::drop_na() |>
  dplyr::mutate(key = tolower(stringr::str_trim(key, side = "both"))) |>
  dplyr::filter(key != "")

# Table of keywords
table(key$key) |>
  as.data.frame() |>
  dplyr::arrange(dplyr::desc(Freq)) |>
  knitr::kable(col.names = c("Keywords", "Frequency")) |>
  kableExtra::scroll_box(width = "55%", height = "500px")
```


## Titles and abstracts

### Word frequency & co-occurrence

Keywords are not necessarily all-encompassing and `r sum(is.na(lit$KEYWORDS))` articles did not even identify any keywords. I therefore turned to text mining the titles and abstracts to glean a little more insights. First, let us tokenize the titles and abstract to get a general idea of the frequency of terms used. In order to find things that we do not already know, I removed the terms that were used in the query of the Web of Science database since they should logically be very frequent. The idea here is to visualize other terms that generally accompany those main terms. I also counted words only once per article to avoid aver-emphasizing words that could be used multiple times within a single abstract or title; this means that the frequencies presented below represent the number of manusript in which a word is used. Below, I present a table with the number of manuscripts in which each word is used (@tbl-words). I also present a wordcloud constrainted to words cited in at least 60 manuscripts (@fig-wordcloud).

```{r}
#| label: tbl-words
#| tbl-cap: Frequency of words used in the titles and abstracts of the literature search on cumulative effects assessment.
# Queried terms to remove
rem <- c(
  "environmental", "cumulative", "effects", "effect", "impacts",
  "impact", "risks", "risk", "assessments", "assessment", "na",
  "elsevier", "reserved"
)

# Frequency of words per year
words_year <- lit |>
  dplyr::mutate(txt = glue::glue("{TITLE}; {ABSTRACT}")) |>
  dplyr::select(uid, year = YEAR, txt) |>
  tidytext::unnest_tokens(word, txt) |>
  dplyr::anti_join(tidytext::stop_words, by = "word") |>
  dplyr::distinct() |>
  dplyr::group_by(word, year) |>
  dplyr::count(word) |>
  dplyr::ungroup() |>
  dplyr::filter(!word %in% rem)

# Word frequency regardless of year
words <- words_year |>
  dplyr::group_by(word) |>
  dplyr::summarize(n = sum(n)) |>
  dplyr::arrange(dplyr::desc(n))

# Table
words |>
  knitr::kable(col.names = c("Words", "Number of articles")) |>
  kableExtra::kable_paper() |>
  kableExtra::kable_styling(position = "center") |>
  kableExtra::scroll_box(width = "55%", height = "500px")
```

```{r}
#| label: fig-wordcloud
#| fig-cap: 'Wordcloud of terms most often used in titles and abstracts of manuscripts on cumulative effects assessments. Note that the following terms were the most frequent, but that it is a by-product of the search queries performed on the Web of Science database: "environmental", "cumulative", "effect(s)", "impact(s)", "risk(s)", "assessment(s)".'
words |>
  dplyr::filter(n > 60) |>
  echarts4r::e_color_range(n, color, colors = viridis::viridis(100)) |>
  echarts4r::e_charts() |>
  echarts4r::e_cloud(word, n, color, shape = "circle", sizeRange = c(15, 38))
```

Now, the literature on cumulative effects assessment has evolved through time and different fields have taken an interest in the topic as the years progressed. For instance, a lot of interest was given to cumulative effects assessment as part of the environmental impact assessment process from 1985 onward, yet cumulative effects have become a point of emphasis in marine ecosystem in the context of marine spatial planning. Let us explore this by plotting the frequency of the most important words in the literature through time.

```{r}
#| label: fig-wdtime
#| fig-cap: 'Number of articles using specific words through time.'
word_time <- tidyr::expand_grid(word = unique(words_year$word), year = min(words_year$year):max(words_year$year)) |>
  dplyr::left_join(words_year, by = c("word", "year")) |>
  dplyr::mutate(n = dplyr::case_when(is.na(n) ~ 0, .default = n)) |>
  dplyr::group_by(word) |>
  dplyr::arrange(word, year) |>
  dplyr::mutate(
    cumcount = cumsum(n),
    word = stringr::str_to_sentence(word)
  ) |>
  dplyr::filter(any(cumcount > 70))


# Chart
word_time |>
  echarts4r::e_charts(year) |>
  echarts4r::e_line(
    cumcount,
    smooth = TRUE,
    symbol = "none",
    endLabel = list(show = TRUE, formatter = "{a}"),
    labelLayout = list(x = "92%", moveOverlap = "shiftY"),
    emphasis = list(focus = "series"),
  ) |>
  echarts4r::e_x_axis(min = 1985, max = 2024, formatter = echarts4r::e_axis_formatter(digits = 0)) |>
  echarts4r::e_tooltip(trigger = "axis", order = "valueDesc") |>
  echarts4r::e_animation(duration = 10000)
```

Finally, some words may co-occur more frequently within a single text without being directly adjacent. Let us explore which words are most often found together within the same document. 

```{r}
#| label: fig-wordco
#| fig-cap: Graph of the relationships between the most frequent words in the title and abstracts of articles focused on cumulative effects assessment.
words <- lit |>
  dplyr::mutate(txt = glue::glue("{TITLE}; {ABSTRACT}")) |>
  dplyr::select(uid, txt) |>
  tidytext::unnest_tokens(word, txt) |>
  dplyr::anti_join(tidytext::stop_words, by = "word") |>
  dplyr::distinct() |>
  dplyr::group_by(uid, word) |>
  dplyr::count(word, sort = TRUE) |>
  dplyr::ungroup() |>
  dplyr::group_by(word) |>
  dplyr::mutate(count = sum(n)) |>
  dplyr::ungroup() |>
  dplyr::filter(!word %in% c("na", "elsevier", "reserved")) |>
  dplyr::filter(count > 50) |>
  dplyr::mutate(word = stringr::str_to_sentence(word))


# Pairwise count
pair_count <- widyr::pairwise_count(words, word, uid, sort = TRUE)

# Pairwise correlation
pair_cor <- widyr::pairwise_cor(words, word, uid, sort = TRUE, upper = FALSE) |>
  dplyr::filter(abs(correlation) > .15)

# Layout
lay <- pair_cor |>
  dplyr::select(from = item1, to = item2, correlation) |>
  tidygraph::as_tbl_graph(directed = FALSE) |>
  ggraph::create_layout(layout = "centrality", centrality = tidygraph::centrality_degree()) |>
  dplyr::select(name, x, y)

# Nodes
nodes <- words |>
  dplyr::select(name = word, value = count) |>
  dplyr::distinct() |>
  dplyr::mutate(
    size = value / 5
  ) |>
  dplyr::left_join(lay, by = "name")

# Edges
edges <- pair_cor |>
  dplyr::select(source = item1, target = item2, value = correlation) |>
  dplyr::mutate(size = value * 10)

# Graph
echarts4r::e_charts() |>
  echarts4r::e_graph(
    layout = "none",
    label = list(show = TRUE, position = "right"),
    lineStyle = list(curveness = 0.3, color = "source"),
    labelLayout = list(hideOverlap = TRUE)
  ) |>
  echarts4r::e_graph_nodes(nodes, name, value, size, xpos = x, ypos = y) |>
  echarts4r::e_graph_edges(edges, source, target, value, size) |>
  echarts4r::e_tooltip()
```

### Bigrams

So far, each word has been considered as a single unit yet words are rarely used in isolation. Let us examine which words tend to follow others by tokenizing by pairs of words rather than single words, *i.e.* bigrams. We can do this for any nnumber of words by tokenizing in *n-grams*, but here I focus on pairs only. This was decided after I explored trigrams and found insights to be limited. For the sake of continuity, I recreate the same table and figures from the previous section, although the code I used is different and more generalizable.

```{r}
#| label: tbl-bigram
#| tbl-cap: Frequency of pairs of words used in the titles and abstracts of the literature search on cumulative effects assessment.
# Function to generate n-gram tokenization
ngram <- function(txt, n) {
  rem <- c(
    tidytext::stop_words$word, "na", "environmental", "cumulative",
    "effects", "effect", "impacts", "impact", "elsevier",
    "risks", "risk", "assessments", "assessment", "reserved"
  )
  txt |>
    tidytext::unnest_tokens(word, text, token = "ngrams", n = n) |>
    tidyr::separate(word, glue::glue("word{1:n}"), sep = " ") |>
    dplyr::filter(!dplyr::if_any(dplyr::starts_with("word"), ~ . %in% rem)) |>
    tidyr::unite(word, dplyr::starts_with("word"), sep = " ") |>
    dplyr::distinct() |>
    dplyr::group_by(word, year) |>
    dplyr::count(word) |>
    dplyr::ungroup()
}

# Abstracts
abstracts <- lit |>
  dplyr::mutate(text = tolower(glue::glue("{TITLE}; {ABSTRACT}"))) |>
  dplyr::select(uid, year = YEAR, text)

# Bigram
bigram <- ngram(abstracts, 2)

# Word frequency regardless of year
words <- bigram |>
  dplyr::group_by(word) |>
  dplyr::summarize(n = sum(n)) |>
  dplyr::arrange(dplyr::desc(n))

# Table
words |>
  knitr::kable(col.names = c("Words", "Number of articles")) |>
  kableExtra::kable_paper() |>
  kableExtra::kable_styling(position = "center") |>
  kableExtra::scroll_box(width = "55%", height = "500px")
```

<br>

```{r}
#| label: fig-wordcloud2
#| fig-cap: 'Wordcloud of pairs of words most often used in titles and abstracts of manuscripts on cumulative effects assessments. Note that the following terms were the most frequent, but that it is a by-product of the search queries performed on the Web of Science database: "environmental", "cumulative", "effect(s)", "impact(s)", "risk(s)", "assessment(s)".'
words |>
  dplyr::filter(n > 7) |>
  echarts4r::e_color_range(n, color, colors = viridis::viridis(100)) |>
  echarts4r::e_charts() |>
  echarts4r::e_cloud(word, n, color, shape = "circle", sizeRange = c(12, 30))
```

<br>

```{r}
#| label: fig-wdtime2
#| fig-cap: 'Number of articles using specific pairs of words through time.'
word_time <- tidyr::expand_grid(word = unique(bigram$word), year = min(bigram$year):max(bigram$year)) |>
  dplyr::left_join(bigram, by = c("word", "year")) |>
  dplyr::mutate(n = dplyr::case_when(is.na(n) ~ 0, .default = n)) |>
  dplyr::group_by(word) |>
  dplyr::arrange(word, year) |>
  dplyr::mutate(
    cumcount = cumsum(n),
    word = stringr::str_to_sentence(word)
  ) |>
  dplyr::filter(any(cumcount > 10))


# Chart
word_time |>
  echarts4r::e_charts(year) |>
  echarts4r::e_line(
    cumcount,
    smooth = TRUE,
    symbol = "none",
    endLabel = list(show = TRUE, formatter = "{a}"),
    labelLayout = list(x = "92%", moveOverlap = "shiftY"),
    emphasis = list(focus = "series"),
  ) |>
  echarts4r::e_x_axis(min = 1985, max = 2024, formatter = echarts4r::e_axis_formatter(digits = 0)) |>
  echarts4r::e_tooltip(trigger = "axis", order = "valueDesc") |>
  echarts4r::e_animation(duration = 10000)
```

<br>

```{r}
#| label: fig-bigramco
#| fig-cap: 'Graph of the relationships between the most frequent pairs of words in the title and abstracts of articles focused on cumulative effects assessment.'
rem <- c(
  tidytext::stop_words$word, "na", "environmental", "cumulative",
  "effects", "effect", "impacts", "impact", "elsevier",
  "risks", "risk", "assessments", "assessment", "reserved"
)
words <- lit |>
  dplyr::mutate(txt = glue::glue("{TITLE}; {ABSTRACT}")) |>
  dplyr::select(uid, txt) |>
  tidytext::unnest_tokens(word, txt, token = "ngrams", n = 2) |>
  tidyr::separate(word, glue::glue("word{1:2}"), sep = " ") |>
  dplyr::filter(!dplyr::if_any(dplyr::starts_with("word"), ~ . %in% rem)) |>
  tidyr::unite(word, dplyr::starts_with("word"), sep = " ") |>
  dplyr::distinct() |>
  dplyr::group_by(uid, word) |>
  dplyr::count(word, sort = TRUE) |>
  dplyr::ungroup() |>
  dplyr::group_by(word) |>
  dplyr::mutate(count = sum(n)) |>
  dplyr::ungroup() |>
  dplyr::filter(!word %in% c("rights reserved")) |>
  dplyr::filter(count > 10) |>
  dplyr::mutate(word = stringr::str_to_sentence(word))

# Pairwise count
pair_count <- widyr::pairwise_count(words, word, uid, sort = TRUE)

# Pairwise correlation
pair_cor <- widyr::pairwise_cor(words, word, uid, sort = TRUE, upper = FALSE)

# Layout
lay <- pair_cor |>
  dplyr::select(from = item1, to = item2, correlation) |>
  tidygraph::as_tbl_graph(directed = FALSE) |>
  # ggraph::create_layout(layout = "pmds", pivots = 5) |>
  ggraph::create_layout(layout = "kk") |>
  dplyr::select(name, x, y)

# Nodes
nodes <- words |>
  dplyr::select(name = word, value = count) |>
  dplyr::distinct() |>
  dplyr::mutate(
    size = value
  ) |>
  dplyr::left_join(lay, by = "name")

# Edges
edges <- pair_cor |>
  dplyr::select(source = item1, target = item2, value = correlation) |>
  dplyr::mutate(size = value * 10)

# Graph
echarts4r::e_charts() |>
  echarts4r::e_graph(
    layout = "none",
    label = list(show = TRUE, position = "right"),
    lineStyle = list(curveness = 0.3, color = "source"),
    labelLayout = list(hideOverlap = TRUE)
  ) |>
  echarts4r::e_graph_nodes(nodes, name, value, size, xpos = x, ypos = y) |>
  echarts4r::e_graph_edges(edges, source, target, value, size) |>
  echarts4r::e_tooltip()
```


### Expressions

Finally, let's go beyond unigrams and bigrams and try to work up a collection of relevant expressions arising from the corpus of recurring expressions in the cumulative effects asssessment literature. After a little exploration, I realized that there are some trigrams such as *ecosystem-based management* and *marine spatial planning*. These are obviously not captured in the unigrams and bigrams, on top of influencing the results of those analyses. To address this, I decided to redo the analysis by evaluating trigrams, bigrams and unigrams while sequentially removing the most prevalent expressions from the abstracts. The results, while still imperfect, are more representative of the literature. 

```{r}
#| label: fig-expressions
#| fig-cap: 'Graph of the relationships between the most frequent expressions words in the title and abstracts of articles focused on cumulative effects assessment'
#| fig-width: 10
#| fig-height: 10
ngram <- function(txt, n) {
  rem <- c(
    tidytext::stop_words$word,
    "na", "reserved", "elsevier" # ,
    # "environmental", "cumulative",
    # "effects", "effect", "impacts", "impact",
    # "risks", "risk", "assessments", "assessment"
  )
  txt |>
    tidytext::unnest_tokens(word, text, token = "ngrams", n = n) |>
    tidyr::separate(word, glue::glue("word{1:n}"), sep = " ") |>
    dplyr::filter(!dplyr::if_any(dplyr::starts_with("word"), ~ . %in% rem)) |>
    tidyr::unite(word, dplyr::starts_with("word"), sep = " ") |>
    dplyr::distinct() |>
    dplyr::group_by(word) |>
    dplyr::mutate(count = dplyr::n()) |>
    dplyr::ungroup()
}

update_abstracts <- function(abstracts, rem) {
  rem <- tolower(rem)
  for (i in seq_len(length(rem))) {
    abstracts <- abstracts |>
      dplyr::mutate(text = stringr::str_replace_all(text, rem[i], " "))
  }
  abstracts
}

abstracts <- lit |>
  dplyr::mutate(
    text = glue::glue("{TITLE}; {ABSTRACT}"),
    text = tolower(text),
    text = stringr::str_replace_all(text, "-", " "),
    text = stringr::str_replace_all(text, "maritime", "marine")
  ) |>
  dplyr::select(uid, text)

# Trigrams
trigram <- ngram(abstracts, 3)
rem <- trigram |>
  dplyr::select(-uid) |>
  dplyr::distinct() |>
  dplyr::arrange(dplyr::desc(count)) |>
  dplyr::filter(count > 3)
trigram <- dplyr::filter(trigram, word %in% rem$word) |>
  dplyr::mutate(count = count / max(count))
abstracts <- update_abstracts(abstracts, rem$word)

# Bigrams
bigram <- ngram(abstracts, 2)
rem <- bigram |>
  dplyr::select(-uid) |>
  dplyr::distinct() |>
  dplyr::arrange(dplyr::desc(count)) |>
  dplyr::filter(count > 6)
bigram <- dplyr::filter(bigram, word %in% rem$word) |>
  dplyr::mutate(count = count / max(count))
abstracts <- update_abstracts(abstracts, rem$word)

# Unigrams
unigram <- ngram(abstracts, 1)
rem <- unigram |>
  dplyr::select(-uid) |>
  dplyr::distinct() |>
  dplyr::arrange(dplyr::desc(count)) |>
  dplyr::filter(count > 70)
unigram <- dplyr::filter(unigram, word %in% rem$word) |>
  dplyr::mutate(count = count / max(count))


# Correlations
words <- dplyr::bind_rows(trigram, bigram, unigram) |>
  dplyr::filter(!word %in% c("results suggest", "resource management", "results", "study")) |> # Manual changes
  dplyr::group_by(uid, word) |>
  dplyr::summarize(count = sum(count)) |>
  dplyr::ungroup()
pair_cor <- widyr::pairwise_cor(words, word, uid, sort = TRUE, upper = FALSE) |>
  dplyr::filter(abs(correlation) > .2)

# Layout
lay <- pair_cor |>
  dplyr::select(from = item1, to = item2, correlation) |>
  tidygraph::as_tbl_graph(directed = FALSE) |>
  ggraph::create_layout(layout = "centrality", centrality = tidygraph::centrality_degree()) |>
  dplyr::select(name, x, y)

# Nodes
nodes <- words |>
  dplyr::select(name = word, value = count) |>
  dplyr::distinct() |>
  dplyr::mutate(
    size = value * 40
  ) |>
  dplyr::left_join(lay, by = "name") |>
  tidyr::drop_na()

# Edges
edges <- pair_cor |>
  dplyr::select(source = item1, target = item2, value = correlation) |>
  dplyr::mutate(size = value * 5)

# Graph
echarts4r::e_charts() |>
  echarts4r::e_graph(
    layout = "none",
    label = list(show = TRUE, position = "right"),
    lineStyle = list(curveness = 0.3, color = "source"),
    labelLayout = list(hideOverlap = TRUE)
  ) |>
  echarts4r::e_graph_nodes(nodes, name, value, size, xpos = x, ypos = y) |>
  echarts4r::e_graph_edges(edges, source, target, value, size) |>
  echarts4r::e_tooltip()
```


## Authors

Now let us do the same with authors to identify who are the most prolific authors in the field and who is collaborating in the field. 

```{r}
#| label: tbl-ceaaut
#| tbl-cap: Number of articles for each author.
authors <- dplyr::bind_rows(lit$AUTHOR, .id = "uid") |>
  dplyr::select(uid, first_name, last_name) |>
  na.omit() |>
  dplyr::mutate(
    first_name = stringr::str_sub(stringr::word(first_name, 1), 1, 1),
    name = glue::glue("{last_name} {first_name}.")
  ) |>
  dplyr::select(uid, name) |>
  dplyr::group_by(name) |>
  dplyr::mutate(count = dplyr::n()) |>
  dplyr::ungroup()


authors |>
  dplyr::count(name) |>
  dplyr::arrange(dplyr::desc(n)) |>
  knitr::kable(col.names = c("Authors", "Frequency")) |>
  kableExtra::kable_paper() |>
  kableExtra::kable_styling(position = "center") |>
  kableExtra::scroll_box(width = "55%", height = "500px")
```

<br>

```{r}
#| label: fig-authors
#| fig-cap: Network of interactions between authors
pair_cor <- authors |>
  dplyr::filter(count > 1) |>
  widyr::pairwise_cor(name, uid, sort = TRUE, upper = FALSE) |>
  dplyr::filter(correlation > 0.2)

# Layout
lay <- pair_cor |>
  dplyr::select(from = item1, to = item2, correlation) |>
  tidygraph::as_tbl_graph(directed = FALSE) |>
  # ggraph::create_layout(layout = "pmds", pivots = 5) |>
  ggraph::create_layout(layout = "kk") |>
  dplyr::select(name, x, y)

# Nodes
nodes <- authors |>
  dplyr::select(name, value = count) |>
  dplyr::filter(name %in% pair_cor$item1 | name %in% pair_cor$item2) |>
  dplyr::distinct() |>
  dplyr::mutate(
    size = value * 2
  ) |>
  dplyr::left_join(lay, by = "name")

# Edges
edges <- pair_cor |>
  dplyr::select(source = item1, target = item2, value = correlation) |>
  dplyr::mutate(size = value)

# Graph
echarts4r::e_charts() |>
  echarts4r::e_graph(
    layout = "none",
    label = list(show = TRUE, position = "right"),
    lineStyle = list(curveness = 0.3, color = "source"),
    labelLayout = list(hideOverlap = TRUE)
  ) |>
  echarts4r::e_graph_nodes(nodes, name, value, size, xpos = x, ypos = y) |>
  echarts4r::e_graph_edges(edges, source, target, value, size) |>
  echarts4r::e_tooltip()
```
